---
title: "AI and our futures"
date: 2023-10-28
---

Let’s first talk about the things LLMs (large language models) can
do at this point. OpenAI’s ChatGPT and Anthropic’s Claude can
write high school essays convincingly, perform at the 88th
%ile on the LSAT, write music, summarize literature, generate ideas
for art and wellness, plan a trip to most places on earth, write a
computer scripts in any programming language, tell jokes in any
language, write assessments and example readings, imitate the voice
and knowledge of people (real and fictional), and help you write a
story. Now, that’s a lot. I personally have only been interfacing
with the free ChatGPT 3.5, but it’s good enough at all those things
to be useful. And – as these chat bots will tell you – they’re
available 24/7 and do basically everyone of the above things
incredibly fast.


	Right
now, ChatGPT is confined to a chat prompt window. But what happens
when it can access your calendar and email and write emails for you?
What happens when it can read your code base and can debug
system-specific problems? What happens when it can be a personal
tutor for anything that can be learned about on the internet? What if
it remembers everything you’ve told it and becomes a best friend?
These are only simple extensions of the core technology of LLMs, yet
they can (and will) be incredibly transformative. 



	The
best example of this right now I think is Khanmigo from KhanAcademy.
From what I can see, they’ve taken ChatGPT and given it specific
contexts and prompts so that it’s tailored for tutoring. In math,
say, it can walk with you step by step through an algebra problem and
answer questions about why some things work, and some things don’t.
It can do the same thing for coding; it can pretend to be literary
characters for English class. It is a personal tutor for a fraction
of the cost and 100x the versatility. KhanAcademy is on the cutting
edge, just like they were with the advent of YouTube (and by the way,
they should be getting tons of government money for this). Maybe not
every other organization can keep up. But in my eyes, LLM’s are so
general purpose, it’s so hard to justify not using them.


	Then
imagine the next version of ChatGPT, or extensions on these
capabilities. Surely it could make an executive summary slideshow.
Surely it could write simple legal documents. Surely it could do
medical diagnoses. But could it build and launch entire websites just
given a sentence as a prompt? Could it edit videos and create graphic
animations? Could it start and run an entire company? These
capacities have improved so rapidly thus far, it’s hard for me to
think that these things are wildly out of the scope of possibilities.
Of course, LLMs drawbacks so far have been the occasional
“hallucinations” and self-contradictions. But its brain gets
bigger, I imagine that it’s tendency to do silly mistakes will
decrease. And possibly, it will become better at performing
multi-step tasks.


	These
technological capabilities sound magical and liberating. But in
practice, who gains from its deployment? The winners and losers from
this AI-based cognitive revolution is a social question. Will
AI-usage be like broadband or oil – prices marked up because of
selfish oligopolies? Or will AI take the social media model –
selling ads, personal information, and eyeballs to subsidize costs?
Or do we treat LLM-access like drinking water or food security, a
basic human necessity?


	Another
question: how do we manage an absurdly powerful surge of automation?
You can imagine that with a highly-trusted, enhanced hypothetical
ChatGPT 6, countless jobs could be made obsolete: accountants,
programmers, designers, lawyers, doctors, scientists, consultants,
investors. Some say that within ten years, any job that can be done
remotely will be feasibly automated by AI. Yet hopefully, we ought
not to fear such a transition as long as we’re flexible. In the
past, most of humanity was devoted to hunter-gathering; then later,
agriculture; and now (in certain countries), cognitive tasks. The
next technological revolution – which could be as transformative as
the industrial revolution – might mean we place more value on
emotional labor, human-to-human contact. Teaching, care-taking,
activism, governance. In a perfect world, we could all learn longer,
retire early, and work in areas we find more meaningful.


	And
here’s a hypothetical: what if LLMs could improve themselves? An
LLM would only need to be above-human at AI research – that
specific domain – to begin to engineer its own code-base. These
models are easily replicable, so once there’s one super-human AI
researcher it can copy itself and produce a billion plus
instantiations. And that means self-improving at an inhumanly fast
speed. AI might zoom from ChatGPT version 10 to version 20 to version
100 and beyond in a matter of weeks. Maybe limited by the amount of
compute and data it can gather. 



	The
potential of such a thing is unfathomable. Self-improving AI is
what they call in sci-fi the Singularity.
ChatGPT-Infinity
would be undoubtedly
be
enough to build physical manifestations of itself in the real world.
It could build technology to
stop climate change, and put that technology in place with swarms of
microbots. It could make
incredible cell-based meat
and end animal exploitation. It
could be an international peace-keeper to end all wars.
But it could also be used by
rogue humans to launch atomic
weapons. It could start a
deadly pandemic to maximize the profits of a vaccine company. It
could – for its own
self-preservation – bulldoze
the planet to make solar panels so it never, ever shuts down.


	Though
they sound far-fetched, these are real possibilities if an AI became
super-intelligent. And they could become a reality very suddenly.
Hence the talk of the “alignment problem”: making sure
super-intelligent AI is onboard and aligned with humanity’s
interests.


	I
don’t know what will happen. And I don’t have any real
prescriptions or recommendations at this point. All I can say it’s
going to be a whacky time over the next couple decades.







Endnote:


Honestly
speaking, AI has been a bewildering curveball for me since the
release of ChatGPT 3 (November 2022) and even before that with
Google’s LaMDA. I’ve been listening to podcasts, reading,
hypothesizing for a while about this. It is both threatening and
exciting to have the prospect of AI taking away “cognitive labor”
jobs as we know it. And I mentally don’t know how to process the
possibility of misaligned AI becoming a super-influential force on
the planet.


	It’s as if we
might soon enter a world of witchcraft and wizardry. It may be an
incredible thing, it may be a horrid thing, or it may be neutral. But
my hunch is that we’re at a tipping point.
